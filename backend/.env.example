# ===============================================
# AI Knowledge Console - Environment Configuration
# ===============================================

# LLM Provider Configuration
# Options: "local" (llama.cpp) or "openrouter"
LLM_PROVIDER=local
LLM_BASE_URL=http://localhost:8080

# Vector Database
CHROMA_PERSIST_DIR=../vectorstore/chroma

# Embedding Model
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ===============================================
# Optional: External API Tools
# ===============================================
GITHUB_TOKEN=
OPENWEATHER_API_KEY=

# ===============================================
# Optional: OAuth Integration URLs
# Required for Gmail, Drive, Slack, Notion
# ===============================================
APP_BASE_URL=http://localhost:8000
FRONTEND_BASE_URL=http://localhost:5173

# ===============================================
# Optional: OAuth Client Credentials
# ===============================================
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
SLACK_CLIENT_ID=
SLACK_CLIENT_SECRET=
NOTION_CLIENT_ID=
NOTION_CLIENT_SECRET=

# ===============================================
# Optional: OpenRouter Configuration
# Use instead of local LLM for hosted inference
# ===============================================
OPENROUTER_API_KEY=
OPENROUTER_MODEL=x-ai/grok-4.1-fast
OPENROUTER_MAX_TOKENS=1024
OPENROUTER_TEMPERATURE=0.7
OPENROUTER_TOP_P=0.9
OPENROUTER_FREQUENCY_PENALTY=0.2
OPENROUTER_PRESENCE_PENALTY=0.0
OPENROUTER_REPETITION_PENALTY=1.1

# ===============================================
# Optional: Application Settings
# ===============================================
ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000
MAX_UPLOAD_MB=25

# Optional: Rate Limiting
RATE_LIMIT_ENABLED=false
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW_SEC=60

# Optional: Database Path
CONVERSATIONS_DB_PATH=backend/conversations.db
